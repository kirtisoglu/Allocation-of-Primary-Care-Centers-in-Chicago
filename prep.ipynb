{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "parent_directory = '/Users/kirtisoglu/Documents/GitHub/Allocation-of-Primary-Care-Centers-in-Chicago'\n",
    "sys.path.append(parent_directory)\n",
    "search_path = '/Users/kirtisoglu/Documents/GitHub/Allocation-of-Primary-Care-Centers-in-Chicago/local_search'\n",
    "sys.path.append(search_path)\n",
    "travel_path = '/Users/kirtisoglu/Documents/GitHub/Allocation-of-Primary-Care-Centers-in-Chicago/traveltime.py'\n",
    "sys.path.append(travel_path)\n",
    "load_path = '/Users/kirtisoglu/Documents/GitHub/Allocation-of-Primary-Care-Centers-in-Chicago/load_data.py'\n",
    "sys.path.append(load_path)\n",
    "plot_path = '/Users/kirtisoglu/Documents/GitHub/Allocation-of-Primary-Care-Centers-in-Chicago/data_prep/plot.py'\n",
    "sys.path.append(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import geojson\n",
    "import json\n",
    "import plotly.express as px\n",
    "import matplotlib as plt\n",
    "from gerrychain import Graph\n",
    "import networkx as nx\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import tools.load_data as load\n",
    "import tools.plot as plot\n",
    "import tools.traveltime as travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import nbimporter as nbim\n",
    "\n",
    "\n",
    "def data_processing():\n",
    "    # Define your function here\n",
    "    pass\n",
    "\n",
    "\n",
    "#Constructs a common Python idiom that prevents certain code from being executed when the script is imported as a module in another script. \n",
    "#The code block under this if-statement will only run if the script is executed directly (not when imported).\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Code inside this block won't run if this notebook is imported using nbimporter\n",
    "    data_processing()\n",
    "    print(\"This prints only if the notebook is executed directly, not when imported.\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "from load_data import load_and_preprocess_data, load_cached_data, cache_data\n",
    "\n",
    "cache_path = 'data_cache.pkl'\n",
    "try:\n",
    "    # Attempt to load cached data\n",
    "    data = load_cached_data(cache_path)\n",
    "    print(\"Loaded data from cache.\")\n",
    "except (FileNotFoundError, IOError):\n",
    "    # Load and preprocess data if cache is not available\n",
    "    data = load_and_preprocess_data('your_data.csv')\n",
    "    cache_data(data, cache_path)\n",
    "    print(\"Loaded data from source and cached it.\")\n",
    "\n",
    "# Now 'data' is ready to use \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirtisoglu/Documents/GitHub/Allocation-of-Primary-Care-Centers-in-Chicago/plot.py:23: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  center={\"lat\": data.geometry.centroid.y.mean(), \"lon\": data.geometry.centroid.x.mean()},\n"
     ]
    }
   ],
   "source": [
    "chicago = gpd.read_file('data/chicago.json')\n",
    "center_lat, center_lon = load.projection(chicago)  # see gerrychain library for that function\n",
    "fig =  plot.fig_blocks(chicago)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual Graph of Census Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' lookup()  #Lookup a node/field attribute. Returns the value of the attribute field at node.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" We use Gerrychain library to construct a dual graph of Census blocks. \"\"\"\n",
    "\n",
    "#graph = Graph.from_geodataframe(chicago)\n",
    "#nx.draw(graph,pos={node:(graph.nodes()[node]['centroid'].x,graph.nodes()[node]['centroid'].y) for node in graph.nodes()}, node_size=20)\n",
    "#graph.to_json(\"GraphToJson.json\")\n",
    "\n",
    "graph = Graph.from_json(\"data/GraphToJson.json\")\n",
    "\n",
    "# Opening JSON file\n",
    "#f = open('GraphToJson.json')\n",
    "# returns JSON object as a dictionary\n",
    "#data = json.load(f)\n",
    "#f.close()\n",
    "#data.keys()\n",
    "\n",
    "\"\"\"adjacency = random.choice(list(data['adjacency']))\n",
    "adjacency\"\"\"\n",
    "\n",
    "\"\"\"node = random.choice(list(graph.nodes))\n",
    "graph.nodes[node]['GEOID20'] \"\"\"\n",
    "\n",
    "\"\"\"first_node = list(graph.nodes)[0]\n",
    "node_attributes = graph.nodes[first_node]\n",
    "print(f\"Attributes for node {first_node}: {node_attributes}\")\"\"\"\n",
    "\n",
    "\"\"\" lookup()  #Lookup a node/field attribute. Returns the value of the attribute field at node.\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The areas of the polygons are included as node attributes (with key `area`).\n",
    "        \n",
    "- The shared perimeter of neighboring polygons are included as edge attributes (with key `shared_perim`).\n",
    "\n",
    "- Nodes corresponding to polygons on the boundary of the union of all the geometries (e.g., the state, if your dataframe describes VTDs) have a    `boundary_node` attribute (set to `True`) and a `boundary_perim` attribute\n",
    "with the length of this \"exterior\" boundary.\n",
    "\n",
    "- Gerrychain library has centroid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Populations from DHC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhc = pd.read_csv('data/dhc_2020.csv')\n",
    "pop_dict = load.get_column(data = dhc, column = 'TOT_POP')  # returns {key: geoid, value: population}\n",
    "load.add_to_graph(graph, pop_dict)  # adds 'population' attributes to nodes\n",
    "load.add_to_data(chicago, pop_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See in API that\n",
    "\n",
    "classgerrychain.partition.GeographicPartition\n",
    "\n",
    "crosses_parts(edge: Tuple)→ bool\n",
    "\n",
    "flip(flips: Dict)→ Partition\n",
    "\n",
    "plot(geometries=None, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random PHCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phc_df, selected_blocks = load.random_phc(chicago)\n",
    "#candidates = load.add_phc(chicago, graph, selected_blocks)\n",
    "#fig = plot.add_phc(fig, phc_df)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Move tree from local_search to tree.py\"\n",
    "#from local_search import tree\n",
    "#uniform = tree.uniform_spanning_tree(graph)\n",
    "#nx.set_edge_attributes(graph, 10, name='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Travel Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"travel_times alculated and saved.\"\n",
    "\n",
    "#for u, v in graph.edges():\n",
    "#    graph[u][v]['time'] = 10\n",
    "#travel_times = travel.travel_time(graph, candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Surprisingly, it uses only 10MB memory, while GraphToJson.json uses 27MB.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" 1) Graph is saved as graph.pkl in prepared_data folder.\"\n",
    "# load.cache_data(graph, file_path='prepared_data/graph.pkl', method = 'pickle')  \n",
    "\" Surprisingly, it uses only 10MB memory, while GraphToJson.json uses 27MB.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 2) Travel times is saved as travel_times.pkl.gz\n",
    "    ujson is loaded in 35 sec, and uses 140MB \n",
    "    pkl.gz is loaded in 16-17 sec, and uses 130MB memory. \"\"\"\n",
    "# load.cache_data(travel_times, file_path='prepared_data/travel_times.pkl.gz', method = 'pickle_gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 3) Chicago data is saved as chicago.pkl.\n",
    "    pkl is loaded in 1 sec, and uses 19MB memory. \n",
    "    Original chicago.json file uses 38MB.\n",
    "    I didn't really get it. pkl is better than json in both memory and loading.\"\"\"\n",
    "    \n",
    "# load.cache_data(chicago, file_path='prepared_data/chicago.pkl', method='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 4) Possible PHC locations (candidates) are saved as candidates.pkl\"\"\"\n",
    "# load.cache_data(candidates, file_path='prepared_data/candidates.pkl', method='pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
